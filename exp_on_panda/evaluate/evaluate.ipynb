{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages/Cython/Distutils/old_build_ext.py:15: DeprecationWarning: dep_util is Deprecated. Use functions from setuptools instead.\n",
      "  from distutils.dep_util import newer, newer_group\n",
      "/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hs/dev_ai/codes/IRPO/exp_on_panda\n",
      "['/home/hs/anaconda3/envs/o2o/lib/python38.zip', '/home/hs/anaconda3/envs/o2o/lib/python3.8', '/home/hs/anaconda3/envs/o2o/lib/python3.8/lib-dynload', '', '/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages', '/home/hs/anaconda3/envs/o2o/lib/python3.8/site-packages/setuptools/_vendor', '/home/hs/dev_ai/codes/IRPO/exp_on_panda']\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import panda_gym\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from stable_baselines3.ppo import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecNormalize\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "\n",
    "PROJECT_ROOT_DIR = Path().absolute().parent\n",
    "print(PROJECT_ROOT_DIR)\n",
    "\n",
    "if str(PROJECT_ROOT_DIR.absolute()) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT_DIR.absolute()))\n",
    "print(sys.path)\n",
    "\n",
    "from utils.sb3_env_utils import make_env\n",
    "from utils.load_data import load_data\n",
    "from utils.sb3_env_wrappers import ScaledObservationWrapper\n",
    "from models.sb3_model import PPOWithBCLoss\n",
    "from utils.sb3_evaluate_kl import evaluate_policy_with_kl\n",
    "from configs.load_config import load_config\n",
    "from utils.register_env import register_my_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env: my-reach\n",
      "BC Exp: iter_4/reacher_10epochs_loss_1_annealing\n",
      "RL Exp: iter_4/reacher_1e7steps_8envs_loss_1_annealing\n",
      "Data: rollout/cache/myreach_from_iter_3_rl_bc_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "# CONFIG_FILE_NAME = \"configs/iter_1/seed1/reacher_annealing.json\"\n",
    "# CONFIG_FILE_NAME = \"configs/iter_2/seed1/reacher_annealing.json\"\n",
    "CONFIG_FILE_NAME = \"configs/iter_4/seed1/reacher_annealing.json\"\n",
    "\n",
    "custom_config = load_config(CONFIG_FILE_NAME)\n",
    "\n",
    "ENV_NAME = custom_config[\"env\"][\"name\"]\n",
    "BC_EXPERIMENT_NAME = custom_config[\"bc\"][\"experiment_name\"]\n",
    "RL_EXPERIMENT_NAME = custom_config[\"rl_bc\"][\"experiment_name\"]\n",
    "BC_EXPERT_DATA_DIR = custom_config[\"bc\"][\"data_cache_dir\"]\n",
    "BC_POLICY_FILE_NAME = custom_config[\"bc\"].get(\"policy_file_save_name\", \"bc_checkpoint\")\n",
    "\n",
    "print(f\"Env: {ENV_NAME}\")\n",
    "print(f\"BC Exp: {BC_EXPERIMENT_NAME}\")\n",
    "print(f\"RL Exp: {RL_EXPERIMENT_NAME}\")\n",
    "print(f\"Data: {BC_EXPERT_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data from /home/hs/dev_ai/codes/IRPO/exp_on_panda/rollout/cache/myreach_from_iter_3_rl_bc_1.csv\n",
      "argv[0]=--background_color_red=0.8745098114013672\n",
      "argv[1]=--background_color_green=0.21176470816135406\n",
      "argv[2]=--background_color_blue=0.1764705926179886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Jan 29 2025 23:19:57\n"
     ]
    }
   ],
   "source": [
    "# Register Environment\n",
    "register_my_env(goal_range=0.3, distance_threshold=0.01, max_episode_steps=50)\n",
    "\n",
    "# Load Data & Environment\n",
    "data_file: Path = PROJECT_ROOT_DIR / BC_EXPERT_DATA_DIR\n",
    "print(f\"load data from {str(data_file.absolute())}\")\n",
    "_, _, _, _, _, obs_scaler = load_data(data_file)\n",
    "\n",
    "env = gym.make(ENV_NAME)\n",
    "env = ScaledObservationWrapper(env=FlattenObservation(env), scaler=obs_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose:  0\n",
      "Loaded BC model from /home/hs/dev_ai/codes/IRPO/exp_on_panda/checkpoints/bc/iter_4/reacher_10epochs_loss_1_annealing/bc_checkpoint\n",
      "verbose:  0\n",
      "Loaded RL model from /home/hs/dev_ai/codes/IRPO/exp_on_panda/checkpoints/rl/iter_4/reacher_1e7steps_8envs_loss_1_annealing/best_model\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "bc_policy_save_dir = PROJECT_ROOT_DIR / \"checkpoints\" / \"bc\" / BC_EXPERIMENT_NAME\n",
    "bc_ppo = PPOWithBCLoss.load(str((bc_policy_save_dir / BC_POLICY_FILE_NAME).absolute()))\n",
    "print(f\"Loaded BC model from {bc_policy_save_dir / BC_POLICY_FILE_NAME}\")\n",
    "\n",
    "rl_bc_policy_save_dir = PROJECT_ROOT_DIR / \"checkpoints\" / \"rl\" / RL_EXPERIMENT_NAME\n",
    "rl_bc_ppo = PPOWithBCLoss.load(str((rl_bc_policy_save_dir / \"best_model\").absolute()), env=env)\n",
    "print(f\"Loaded RL model from {rl_bc_policy_save_dir / 'best_model'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KL (Teacher=BC, Student=RL, Sample=BC)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hs/dev_ai/codes/IRPO/exp_on_panda/utils/sb3_evaluate_kl.py:80: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-4.5, 1.3601470508735443, 6.0165632206744515e+23, 2.3404524488882585)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate KL (Teacher: BC, Student: RL, Sample: BC)\n",
    "print(\"Evaluating KL (Teacher=BC, Student=RL, Sample=BC)...\")\n",
    "evaluate_policy_with_kl(model_teacher=bc_ppo, model_student=rl_bc_ppo, sample_model=bc_ppo, env=env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KL (Teacher=RL, Student=BC, Sample=RL)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hs/dev_ai/codes/IRPO/exp_on_panda/utils/sb3_evaluate_kl.py:80: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-4.0, 1.0, 742415141400.2032, 1.7063520585745573)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate KL (Teacher: RL, Student: BC, Sample: RL)\n",
    "print(\"Evaluating KL (Teacher=RL, Student=BC, Sample=RL)...\")\n",
    "evaluate_policy_with_kl(model_teacher=rl_bc_ppo, model_student=bc_ppo, sample_model=rl_bc_ppo, env=env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KL (Teacher=BC, Student=RL, Sample=RL)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hs/dev_ai/codes/IRPO/exp_on_panda/utils/sb3_evaluate_kl.py:80: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Mean Reward: -3.97 +/- 1.49\n",
      "KL (Teacher->Student): 17907037.8099\n",
      "Action Dist KL: 1.5006\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate KL (Teacher: BC, Student: RL, Sample: RL) and print stats\n",
    "print(\"Evaluating KL (Teacher=BC, Student=RL, Sample=RL)...\")\n",
    "mean_reward, std_reward, mean_kl, mean_act_dist_kl = evaluate_policy_with_kl(\n",
    "    model_teacher=bc_ppo, \n",
    "    model_student=rl_bc_ppo, \n",
    "    sample_model=rl_bc_ppo, \n",
    "    env=env, \n",
    "    n_eval_episodes=100\n",
    ")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Mean Reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "print(f\"KL (Teacher->Student): {mean_kl:.4f}\")\n",
    "print(f\"Action Dist KL: {mean_act_dist_kl:.4f}\")\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "o2o",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
